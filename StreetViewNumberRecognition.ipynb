{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "from shutil import copyfile\n",
    "import IPython.core.debugger\n",
    "import tarfile\n",
    "import h5py\n",
    "import random\n",
    "from PIL import Image\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dbg = IPython.core.debugger.Pdb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = 'http://ufldl.stanford.edu/housenumbers/'\n",
    "TRAIN = 'train.tar.gz'\n",
    "TEST = 'test.tar.gz'\n",
    "EXTRA = 'extra.tar.gz'\n",
    "def maybe_download(filename, work_dir):\n",
    "    \"\"\"Download the data from source_url, unless it's already here\n",
    "    \n",
    "        Args:\n",
    "            filename: string, name of the file in the directory.\n",
    "            work_dir: string, path to working directory.\n",
    "        Returns:\n",
    "            Path to resulting file.\n",
    "            \n",
    "    \"\"\"\n",
    "    if not os.path.exists(work_dir):\n",
    "        os.mkdir(work_dir)\n",
    "    file_path = os.path.join(work_dir,filename)\n",
    "    if not os.path.exists(file_path):\n",
    "        temp_file, _ = urlretrieve(url+filename)\n",
    "        copyfile(temp_file, file_path)\n",
    "\n",
    "    print('Found and verified:', filename, os.stat(file_path).st_size, 'bytes')\n",
    "    return file_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found and verified: train.tar.gz 404141560 bytes\n",
      "Found and verified: test.tar.gz 276555967 bytes\n",
      "Found and verified: extra.tar.gz 1955489752 bytes\n",
      "SVHN/test.tar.gz\n"
     ]
    }
   ],
   "source": [
    "work_dir = 'SVHN/'\n",
    "train_path = maybe_download(TRAIN,work_dir)\n",
    "test_path = maybe_download(TEST,work_dir)\n",
    "extra_path = maybe_download(EXTRA, work_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVHN/train already present - Skipping extraction of SVHN/train.tar.gz\n",
      "SVHN/test already present - Skipping extraction of SVHN/test.tar.gz\n"
     ]
    }
   ],
   "source": [
    "def maybe_extract(filename):\n",
    "    root = os.path.splitext(os.path.splitext(filename)[0])[0]\n",
    "    if os.path.isdir(root):\n",
    "        print('%s already present - Skipping extraction of %s' %(root, filename))\n",
    "    else:\n",
    "        print('Extracting data for %s. This may take a while. Please wait.' %root)\n",
    "        tar = tarfile.open(filename)\n",
    "        sys.stdout.flush()\n",
    "        tar.extractall(work_dir)\n",
    "        print('Extracting done!')\n",
    "        tar.close\n",
    "    return root\n",
    "train_dir = maybe_extract(train_path)\n",
    "test_dir = maybe_extract(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ExampleReader(object):\n",
    "    def __init__(self, path_to_image_files):\n",
    "        self._path_to_image_files = path_to_image_files\n",
    "        self._num_examples = len(self._path_to_image_files)\n",
    "        self._example_pointer = 0\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_attrs(digit_struct_mat_file, index):\n",
    "        \"\"\"\n",
    "        Returns a dictionary which contains keys: label, left, top, width and height, each key has multiple values.\n",
    "        \"\"\"\n",
    "        attrs = {}\n",
    "        f = digit_struct_mat_file\n",
    "        item = f['digitStruct']['bbox'][index].item()\n",
    "        for key in ['label', 'left', 'top', 'width', 'height']:\n",
    "            attr = f[item][key]\n",
    "            values = [f[attr.value[i].item()].value[0][0]\n",
    "                      for i in range(len(attr))] if len(attr) > 1 else [attr.value[0][0]]\n",
    "            attrs[key] = values\n",
    "        return attrs\n",
    "\n",
    "    @staticmethod\n",
    "    def _preprocess(image, bbox_left, bbox_top, bbox_width, bbox_height):\n",
    "        cropped_left, cropped_top, cropped_width, cropped_height = (int(round(bbox_left - 0.15 * bbox_width)),\n",
    "                                                                    int(round(bbox_top - 0.15 * bbox_height)),\n",
    "                                                                    int(round(bbox_width * 1.3)),\n",
    "                                                                    int(round(bbox_height * 1.3)))\n",
    "        image = image.crop([cropped_left, cropped_top, cropped_left + cropped_width, cropped_top + cropped_height])\n",
    "        image = image.resize([64, 64])\n",
    "        return image\n",
    "\n",
    "    @staticmethod\n",
    "    def _int64_feature(value):\n",
    "        return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "    @staticmethod\n",
    "    def _float_feature(value):\n",
    "        return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n",
    "\n",
    "    @staticmethod\n",
    "    def _bytes_feature(value):\n",
    "        return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "    def read_and_convert(self, digit_struct_mat_file):\n",
    "        \"\"\"\n",
    "        Read and convert to example, returns None if no data is available.\n",
    "        \"\"\"\n",
    "#         dbg.set_trace()\n",
    "        if self._example_pointer == self._num_examples:\n",
    "            return None\n",
    "        path_to_image_file = self._path_to_image_files[self._example_pointer]\n",
    "        index = int(path_to_image_file.split('/')[-1].split('.')[0]) - 1\n",
    "        self._example_pointer += 1\n",
    "\n",
    "        attrs = ExampleReader._get_attrs(digit_struct_mat_file, index)\n",
    "        label_of_digits = attrs['label']\n",
    "        length = len(label_of_digits)\n",
    "        if length > 5:\n",
    "            # skip this example\n",
    "            return self.read_and_convert(digit_struct_mat_file)\n",
    "\n",
    "        digits = [10, 10, 10, 10, 10]   # digit 10 represents no digit\n",
    "        for idx, label_of_digit in enumerate(label_of_digits):\n",
    "            digits[idx] = int(label_of_digit if label_of_digit != 10 else 0)    # label 10 is essentially digit zero\n",
    "\n",
    "        attrs_left, attrs_top, attrs_width, attrs_height = map(lambda x: [int(i) for i in x], [attrs['left'], attrs['top'], attrs['width'], attrs['height']])\n",
    "        min_left, min_top, max_right, max_bottom = (min(attrs_left),\n",
    "                                                    min(attrs_top),\n",
    "                                                    max(map(lambda x, y: x + y, attrs_left, attrs_width)),\n",
    "                                                    max(map(lambda x, y: x + y, attrs_top, attrs_height)))\n",
    "        center_x, center_y, max_side = ((min_left + max_right) / 2.0,\n",
    "                                        (min_top + max_bottom) / 2.0,\n",
    "                                        max(max_right - min_left, max_bottom - min_top))\n",
    "        bbox_left, bbox_top, bbox_width, bbox_height = (center_x - max_side / 2.0,\n",
    "                                                        center_y - max_side / 2.0,\n",
    "                                                        max_side,\n",
    "                                                        max_side)\n",
    "        image = np.array(ExampleReader._preprocess(Image.open(path_to_image_file), bbox_left, bbox_top, bbox_width, bbox_height)).tobytes()\n",
    "\n",
    "        example = tf.train.Example(features=tf.train.Features(feature={\n",
    "            'image': ExampleReader._bytes_feature(image),\n",
    "            'length': ExampleReader._int64_feature(length),\n",
    "            'digits': tf.train.Feature(int64_list=tf.train.Int64List(value=digits))\n",
    "        }))\n",
    "        return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_to_tfrecords(dataset_and_digit_struct, tfrecords, writer_callback):\n",
    "    num_examples = []\n",
    "    writers = []\n",
    "    \n",
    "    for record in tfrecords:\n",
    "        num_examples.append(0)\n",
    "        writers.append(tf.python_io.TFRecordWriter(record))\n",
    "    for dataset, digit_struct in dataset_and_digit_struct:\n",
    "        image_files = tf.gfile.Glob(os.path.join(dataset, '*.png'))\n",
    "        total_files = len(image_files)\n",
    "        print('%d files found in %s' %(total_files,dataset))\n",
    "#         dbg.set_trace()\n",
    "        with h5py.File(digit_struct,'r') as f:\n",
    "            example_reader = ExampleReader(image_files)\n",
    "            for index, image_file in enumerate(image_files):\n",
    "                if index%10 == 0:\n",
    "                    print('(%d/%d) processing %s' % (index+1, total_files, image_file))\n",
    "                example = example_reader.read_and_convert(f)\n",
    "                if example is None:\n",
    "                    break\n",
    "                idx = writer_callback(tfrecords)\n",
    "                writers[idx].write(example.SerializeToString())\n",
    "                num_examples[idx] += 1\n",
    "    for writer in writers:\n",
    "        writer.close()\n",
    "    return num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_tfrecords_meta_file(num_train_examples, num_val_examples, num_test_examples,\n",
    "                               path_to_tfrecords_meta_file):\n",
    "    print 'Saving meta file to %s...' % path_to_tfrecords_meta_file\n",
    "    meta = Meta()\n",
    "    meta.num_train_examples = num_train_examples\n",
    "    meta.num_val_examples = num_val_examples\n",
    "    meta.num_test_examples = num_test_examples\n",
    "    meta.save(path_to_tfrecords_meta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file SVHN/train.tfrecords already exists\n",
      "29964 3437\n",
      "The file SVHN/test.tfrecords already exists\n",
      "13068\n"
     ]
    }
   ],
   "source": [
    "train_struct_mat = os.path.join(train_dir, 'digitStruct.mat')\n",
    "test_struct_mat = os.path.join(test_dir, 'digitStruct.mat')\n",
    "train_tfrecords = os.path.join(work_dir, 'train.tfrecords')\n",
    "valid_tfrecords = os.path.join(work_dir, 'valid.tfrecords')\n",
    "test_tfrecords = os.path.join(work_dir, 'test.tfrecords')\n",
    "# First assume the tfrecords is not existed yet.\n",
    "if not os.path.exists(train_tfrecords):\n",
    "    print ('Processing training and validation data...')\n",
    "    [num_train_examples, num_val_examples] = convert_to_tfrecords([(train_dir,train_struct_mat)],[train_tfrecords, valid_tfrecords], lambda paths:0 if random.random()>0.1 else 1)\n",
    "else: \n",
    "    print('The file %s already exists'% train_tfrecords)\n",
    "print (num_train_examples, num_val_examples)\n",
    "if not os.path.exists(test_tfrecords):\n",
    "    print('Processing testing data...')\n",
    "    [num_test_examples] = convert_to_tfrecords([(test_dir,test_struct_mat)],[test_tfrecords],lambda paths: 0)\n",
    "else:\n",
    "    print('The file %s already exists'% test_tfrecords)\n",
    "print(num_test_examples)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata already present - Skipping pickling.\n"
     ]
    }
   ],
   "source": [
    "metadata = {\n",
    "    'num_train_examples' : num_train_examples,\n",
    "    'num_val_examples' : num_val_examples,\n",
    "    'num_test_examples' : num_test_examples\n",
    "}\n",
    "# root = '.'\n",
    "\n",
    "def maybe_pickle(dataset,dest_dir,filename, force= False):\n",
    "    \"\"\"\n",
    "    pickle the dataset as the pickle file\n",
    "    \n",
    "    Args:\n",
    "         dataset: the dataset need to pickle.\n",
    "         dest_dir: path where you save the pickle files.\n",
    "         filename: str represents the name of the dataset\n",
    "    Return:\n",
    "         dataset_names: the name of the pickle file\n",
    "    \"\"\"\n",
    "\n",
    "    file_path = os.path.join(dest_dir, filename) + '.pickle'\n",
    "    if os.path.exists(file_path) and not force:\n",
    "        print('%s already present - Skipping pickling.' % filename)\n",
    "    else:\n",
    "        print('Pickling %s.' % file_path)\n",
    "        try:\n",
    "            with open(file_path, 'wb') as f:\n",
    "                pickle.dump(dataset, f, pickle.HIGHEST_PROTOCOL)\n",
    "        except Exception as e:\n",
    "            print('Unable to save data to', filename, ':', e)\n",
    "    return file_path\n",
    "\n",
    "meta_pickle = maybe_pickle(metadata, work_dir, 'metadata' )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executing foo(<__main__.A object at 0x121f3add8>, 1)\n",
      "executing class_foo(<class '__main__.A'>,1)\n",
      "executing class_foo(<class '__main__.A'>,2)\n",
      "executing static_foo(1)\n",
      "executing static_foo(hi)\n",
      "<bound method A.foo of <__main__.A object at 0x121f3add8>>\n",
      "<bound method A.class_foo of <class '__main__.A'>>\n",
      "<bound method A.class_foo of <class '__main__.A'>>\n",
      "<function A.static_foo at 0x121f98ea0>\n",
      "<function A.static_foo at 0x121f98ea0>\n"
     ]
    }
   ],
   "source": [
    "class A(object):\n",
    "    def foo(self,x):\n",
    "        print(\"executing foo(%s, %s)\"%(self,x)) #self --> __main__.A object at...\n",
    "    @classmethod\n",
    "    def class_foo(cls,x): #cls --> __main__.A\n",
    "        print(\"executing class_foo(%s,%s)\"%(cls,x))\n",
    "    \n",
    "    @staticmethod\n",
    "    def static_foo(x):\n",
    "        print(\"executing static_foo(%s)\"%x)\n",
    "a=A()\n",
    "a.foo(1)\n",
    "\"\"\"With classmethods, the class of the object instance is\n",
    "   implicityly passed as the first argument instead of self.\n",
    "   If you define something to be a classmethod it is probably\n",
    "   because you intend to call it from the class rather than\n",
    "   from a class instance.\"\"\"\n",
    "a.class_foo(1)\n",
    "A.class_foo(2)\n",
    "# A.foo(2)\n",
    "a.static_foo(1)\n",
    "A.static_foo('hi')\n",
    "print(a.foo)\n",
    "print(a.class_foo)\n",
    "print(A.class_foo)\n",
    "print(a.static_foo)\n",
    "print(A.static_foo)\n",
    "\n",
    "\"\"\"classmethod must have a reference to a class object as the first parameter,\n",
    "   whereas staticmethod can have no parameters at all.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.0\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('SVHN/train/digitStruct.mat', 'r') as digit_struct_mat_file:\n",
    "    item = digit_struct_mat_file['digitStruct']['bbox'][0].item()\n",
    "    label = digit_struct_mat_file[item]['label']\n",
    "    print(digit_struct_mat_file[label[1].item()][0][0])\n",
    "#     for i in digit_struct_mat_file[item].__iter__():\n",
    "#         print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
